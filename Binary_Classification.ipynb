{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d273131",
   "metadata": {},
   "source": [
    "# Clasificaci´ on de opiniones cinematogr´ aficas con Machine Learning \n",
    "## Contexto del problema \n",
    "El auge de las plataformas de streaming y comunidades cin´ efilas ha generado una gran cantidad de datos sobre pel´ ıculas, incluyendo informaci´ on t´ ecnica, sinopsis y reacciones del p´ublico. En este trabajo se utilizar´ a un conjunto de datos del dominio cinematogr´ afico para resolver dos tareas de clasificaci´ on: una clasificaci´ on binaria que predice una opini´ on emitida por un p´ ublico cin´ efilo exigente, y una clasificaci´ on multiclase que busca predecir el g´ enero principal de una pel´ ıcula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "131609bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACER IMPORTS\n",
    "# Cargar datasets\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./datasets/movies_train.csv')  # Cargar el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855fcf73",
   "metadata": {},
   "source": [
    "## Exploracion y Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5420ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3602 entries, 0 to 3601\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   budget             3602 non-null   int64  \n",
      " 1   keywords           3298 non-null   object \n",
      " 2   original_language  3602 non-null   object \n",
      " 3   original_title     3602 non-null   object \n",
      " 4   overview           3600 non-null   object \n",
      " 5   popularity         3602 non-null   float64\n",
      " 6   release_date       3601 non-null   object \n",
      " 7   revenue            3602 non-null   int64  \n",
      " 8   runtime            3600 non-null   float64\n",
      " 9   status             3602 non-null   object \n",
      " 10  vote_count         3602 non-null   int64  \n",
      " 11  director           3579 non-null   object \n",
      " 12  main_genre_top10   3602 non-null   object \n",
      " 13  opinion            3602 non-null   int64  \n",
      "dtypes: float64(2), int64(4), object(8)\n",
      "memory usage: 394.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "budget                 0\n",
       "keywords             304\n",
       "original_language      0\n",
       "original_title         0\n",
       "overview               2\n",
       "popularity             0\n",
       "release_date           1\n",
       "revenue                0\n",
       "runtime                2\n",
       "status                 0\n",
       "vote_count             0\n",
       "director              23\n",
       "main_genre_top10       0\n",
       "opinion                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Mostrar las primeras filas del DataFrame para verificar que se ha cargado correctamente\n",
    "df.info() # Mostrar información general del DataFrame, incluyendo tipos de datos y valores nulos\n",
    "df.isna().sum() # Comprobar si hay valores nulos en el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc61cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def clean_data(df, is_train=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Eliminar nulos críticos SOLO en entrenamiento ---\n",
    "    if is_train:\n",
    "        df.dropna(subset=['runtime', 'overview', 'release_date'], inplace=True)\n",
    "\n",
    "    # --- Completar nulos ---\n",
    "    df['keywords'] = df['keywords'].fillna('')\n",
    "    df['director'] = df['director'].fillna('unknown')\n",
    "\n",
    "    # --- Fecha como año ---\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "    df['release_year'] = df['release_date'].dt.year.fillna(0).astype(int)\n",
    "\n",
    "    # --- Codificar columnas categóricas ---\n",
    "    label_cols = ['original_language', 'status', 'director', 'main_genre_top10']\n",
    "    for col in label_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))  # Asegura que no haya problemas con NaN\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b23cf7",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9f6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, feature_cols, target_col, test_size=0.2, random_state=42):\n",
    "    X = df[feature_cols]\n",
    "    y = df[target_col]\n",
    "\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d27bcc",
   "metadata": {},
   "source": [
    "## Definicion de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57370393",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b554606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_random_forest(X_train, X_test, y_train, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print(\"Reporte de clasificación:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return rf, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812989f0",
   "metadata": {},
   "source": [
    "### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62520a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def train_logistic_regression(X_train, X_test, y_train, y_test):\n",
    "    lr = LogisticRegression(penalty=None, max_iter=1000, random_state=42, solver='lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    print(\"Reporte de clasificación - Logistic Regression:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return lr, y_pred\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1771847",
   "metadata": {},
   "source": [
    "### Arbol de Desision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62fcb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X_train, X_test, y_train, y_test):\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = dt.predict(X_test)\n",
    "\n",
    "    print(\"Reporte de clasificación - Decision Tree:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return dt, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8055e3",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5901d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradient_boosting(X_train, X_test, y_train, y_test):\n",
    "    gbc = GradientBoostingClassifier(random_state=42)\n",
    "    gbc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gbc.predict(X_test)\n",
    "\n",
    "    print(\"Reporte de clasificación - Gradient Boosting:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return gbc, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b2c44",
   "metadata": {},
   "source": [
    "## Uso de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1468bd",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07699fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       365\n",
      "           1       0.70      0.68      0.69       356\n",
      "\n",
      "    accuracy                           0.70       721\n",
      "   macro avg       0.70      0.70      0.70       721\n",
      "weighted avg       0.70      0.70      0.70       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean = clean_data(df)\n",
    "\n",
    "feature_cols = ['budget', 'popularity', 'revenue', 'runtime', 'vote_count',\n",
    "                'original_language', 'status', 'director', 'main_genre_top10', 'release_year']\n",
    "\n",
    "target_col = 'opinion'\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df_clean, feature_cols, target_col)\n",
    "\n",
    "model, y_pred = train_random_forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#SUBIR A KAGGLE:\n",
    "#kaggle_submission(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1466ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación - Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71       365\n",
      "           1       0.71      0.62      0.66       356\n",
      "\n",
      "    accuracy                           0.68       721\n",
      "   macro avg       0.69      0.68      0.68       721\n",
      "weighted avg       0.69      0.68      0.68       721\n",
      "\n",
      "Reporte de clasificación - Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64       365\n",
      "           1       0.63      0.66      0.64       356\n",
      "\n",
      "    accuracy                           0.64       721\n",
      "   macro avg       0.64      0.64      0.64       721\n",
      "weighted avg       0.64      0.64      0.64       721\n",
      "\n",
      "Reporte de clasificación:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       365\n",
      "           1       0.70      0.68      0.69       356\n",
      "\n",
      "    accuracy                           0.70       721\n",
      "   macro avg       0.70      0.70      0.70       721\n",
      "weighted avg       0.70      0.70      0.70       721\n",
      "\n",
      "Reporte de clasificación - Gradient Boosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       365\n",
      "           1       0.72      0.68      0.70       356\n",
      "\n",
      "    accuracy                           0.71       721\n",
      "   macro avg       0.71      0.71      0.71       721\n",
      "weighted avg       0.71      0.71      0.71       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "model_lr, y_pred_lr = train_logistic_regression(X_train, X_test, y_train, y_test)\n",
    "kaggle_submission(model_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "863ab57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación - Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64       365\n",
      "           1       0.63      0.66      0.64       356\n",
      "\n",
      "    accuracy                           0.64       721\n",
      "   macro avg       0.64      0.64      0.64       721\n",
      "weighted avg       0.64      0.64      0.64       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "model_dt, y_pred_dt = train_decision_tree(X_train, X_test, y_train, y_test)\n",
    "kaggle_submission(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4d0c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       365\n",
      "           1       0.70      0.68      0.69       356\n",
      "\n",
      "    accuracy                           0.70       721\n",
      "   macro avg       0.70      0.70      0.70       721\n",
      "weighted avg       0.70      0.70      0.70       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (tu ya lo tienes)\n",
    "model_rf, y_pred_rf = train_random_forest(X_train, X_test, y_train, y_test)\n",
    "kaggle_submission(model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4114565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación - Gradient Boosting:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       365\n",
      "           1       0.72      0.68      0.70       356\n",
      "\n",
      "    accuracy                           0.71       721\n",
      "   macro avg       0.71      0.71      0.71       721\n",
      "weighted avg       0.71      0.71      0.71       721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "model_gbc, y_pred_gbc = train_gradient_boosting(X_train, X_test, y_train, y_test)\n",
    "kaggle_submission(model_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718c78b",
   "metadata": {},
   "source": [
    "## Subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d13da150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kaggle_submission(model):\n",
    "    # Cargar y limpiar el dataset de test\n",
    "    df_test = pd.read_csv('./datasets/movies_test.csv')\n",
    "    df_test = df_test.dropna(subset=['id'])  # eliminar posibles filas en blanco\n",
    "    df_test = clean_data(df_test, False)  # aplicar transformaciones del train\n",
    "\n",
    "    # Seleccionar las columnas que el modelo espera\n",
    "    feature_cols = ['budget', 'popularity', 'revenue', 'runtime', 'vote_count',\n",
    "                    'original_language', 'status', 'director', 'main_genre_top10', 'release_year']\n",
    "    X_test_final = df_test[feature_cols]\n",
    "\n",
    "    # Predecir\n",
    "    predictions = model.predict(X_test_final)\n",
    "\n",
    "    # Crear el DataFrame de submission\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': df_test['id'],        # ID en mayúscula si es para Kaggle\n",
    "        'Rating': predictions       # Rating en mayúscula si es para Kaggle\n",
    "    })\n",
    "\n",
    "    # Verificar cantidad de filas\n",
    "    assert len(submission_df) == 1201, f\"Submission tiene {len(submission_df)} filas, deberían ser 1201\"\n",
    "\n",
    "    # Guardar sin índice\n",
    "    submission_df.to_csv('submission.csv', index=False, header=True)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90837754",
   "metadata": {},
   "source": [
    "# PARTE 2 : Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fcb5f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def train_neural_network_for_genre(df, feature_cols=None, target_col='main_genre_top10',\n",
    "                                   test_size=0.2, random_state=42, epochs=30, batch_size=32):\n",
    "    \"\"\"\n",
    "    Entrena una red neuronal para predecir la variable categórica 'main_genre_top10'.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: dataframe limpio con datos.\n",
    "    - feature_cols: lista de columnas a usar como features (si None usa columnas por defecto).\n",
    "    - target_col: nombre de la columna objetivo.\n",
    "    - test_size: proporción para test.\n",
    "    - random_state: semilla para reproducibilidad.\n",
    "    - epochs: número de épocas para entrenar.\n",
    "    - batch_size: tamaño de batch para entrenamiento.\n",
    "    \n",
    "    Retorna:\n",
    "    - model: modelo Keras entrenado.\n",
    "    - history: historial de entrenamiento.\n",
    "    - accuracy: precisión en el conjunto de test.\n",
    "    \"\"\"\n",
    "\n",
    "    if feature_cols is None:\n",
    "        feature_cols = ['budget', 'popularity', 'revenue', 'runtime', 'vote_count',\n",
    "                        'original_language', 'status', 'director', 'release_year']\n",
    "\n",
    "    X = df[feature_cols]\n",
    "    y = df[target_col]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # One-hot encode target\n",
    "    num_classes = len(np.unique(y))\n",
    "    y_cat = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_cat,\n",
    "                                                        test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=2)\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return model, history, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2847722a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 - 2s - 24ms/step - accuracy: 0.2765 - loss: 2.1619 - val_accuracy: 0.3085 - val_loss: 2.0331\n",
      "Epoch 2/30\n",
      "72/72 - 0s - 4ms/step - accuracy: 0.3377 - loss: 1.9727 - val_accuracy: 0.3189 - val_loss: 1.9898\n",
      "Epoch 3/30\n",
      "72/72 - 0s - 4ms/step - accuracy: 0.3507 - loss: 1.9406 - val_accuracy: 0.3137 - val_loss: 1.9709\n",
      "Epoch 4/30\n",
      "72/72 - 0s - 4ms/step - accuracy: 0.3459 - loss: 1.9208 - val_accuracy: 0.3224 - val_loss: 1.9609\n",
      "Epoch 5/30\n",
      "72/72 - 0s - 4ms/step - accuracy: 0.3459 - loss: 1.8934 - val_accuracy: 0.3206 - val_loss: 1.9456\n",
      "Epoch 6/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3546 - loss: 1.8887 - val_accuracy: 0.3154 - val_loss: 1.9452\n",
      "Epoch 7/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3607 - loss: 1.8727 - val_accuracy: 0.3224 - val_loss: 1.9351\n",
      "Epoch 8/30\n",
      "72/72 - 0s - 4ms/step - accuracy: 0.3650 - loss: 1.8640 - val_accuracy: 0.3241 - val_loss: 1.9330\n",
      "Epoch 9/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3715 - loss: 1.8724 - val_accuracy: 0.3224 - val_loss: 1.9239\n",
      "Epoch 10/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3676 - loss: 1.8548 - val_accuracy: 0.3224 - val_loss: 1.9194\n",
      "Epoch 11/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3715 - loss: 1.8416 - val_accuracy: 0.3206 - val_loss: 1.9248\n",
      "Epoch 12/30\n",
      "72/72 - 0s - 4ms/step - accuracy: 0.3928 - loss: 1.8336 - val_accuracy: 0.3154 - val_loss: 1.9207\n",
      "Epoch 13/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3746 - loss: 1.8261 - val_accuracy: 0.3241 - val_loss: 1.9156\n",
      "Epoch 14/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3659 - loss: 1.8288 - val_accuracy: 0.3293 - val_loss: 1.9237\n",
      "Epoch 15/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3793 - loss: 1.8335 - val_accuracy: 0.3189 - val_loss: 1.9221\n",
      "Epoch 16/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3733 - loss: 1.8133 - val_accuracy: 0.3189 - val_loss: 1.9206\n",
      "Epoch 17/30\n",
      "72/72 - 0s - 4ms/step - accuracy: 0.3728 - loss: 1.8119 - val_accuracy: 0.3224 - val_loss: 1.9229\n",
      "Epoch 18/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3737 - loss: 1.8128 - val_accuracy: 0.3241 - val_loss: 1.9262\n",
      "Epoch 19/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3811 - loss: 1.8023 - val_accuracy: 0.3310 - val_loss: 1.9327\n",
      "Epoch 20/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3885 - loss: 1.8068 - val_accuracy: 0.3293 - val_loss: 1.9283\n",
      "Epoch 21/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3776 - loss: 1.8061 - val_accuracy: 0.3328 - val_loss: 1.9242\n",
      "Epoch 22/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3898 - loss: 1.7924 - val_accuracy: 0.3276 - val_loss: 1.9300\n",
      "Epoch 23/30\n",
      "72/72 - 0s - 6ms/step - accuracy: 0.3915 - loss: 1.7901 - val_accuracy: 0.3380 - val_loss: 1.9176\n",
      "Epoch 24/30\n",
      "72/72 - 0s - 6ms/step - accuracy: 0.3785 - loss: 1.7954 - val_accuracy: 0.3345 - val_loss: 1.9265\n",
      "Epoch 25/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3754 - loss: 1.7917 - val_accuracy: 0.3328 - val_loss: 1.9217\n",
      "Epoch 26/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3880 - loss: 1.7740 - val_accuracy: 0.3293 - val_loss: 1.9261\n",
      "Epoch 27/30\n",
      "72/72 - 0s - 6ms/step - accuracy: 0.3867 - loss: 1.7875 - val_accuracy: 0.3258 - val_loss: 1.9234\n",
      "Epoch 28/30\n",
      "72/72 - 0s - 6ms/step - accuracy: 0.3889 - loss: 1.7742 - val_accuracy: 0.3362 - val_loss: 1.9201\n",
      "Epoch 29/30\n",
      "72/72 - 0s - 6ms/step - accuracy: 0.3863 - loss: 1.7782 - val_accuracy: 0.3362 - val_loss: 1.9189\n",
      "Epoch 30/30\n",
      "72/72 - 0s - 5ms/step - accuracy: 0.3893 - loss: 1.7823 - val_accuracy: 0.3362 - val_loss: 1.9238\n",
      "Test Accuracy: 0.3426\n"
     ]
    }
   ],
   "source": [
    "model, history, acc = train_neural_network_for_genre(df_clean)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
